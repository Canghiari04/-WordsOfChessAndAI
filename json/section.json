[
  {
    "../articles/16DavidNetanyahuWolf.pdf": {
      "Abstract": "Abstract. We present an end-to-end learning method for chess, relying on\nleep neural networks. Without any a priori knowledge, in particular without\nany knowledge regarding the rules of chess, a deep neural network is trained\nusing a combination of unsupervised pretraining and supervised training. The\nunsupervised training extracts high level features from a given position, and\nthe supervised training learns to compare two chess positions and select the\nmore favorable one. The training relies entirely on datasets of several million\nchess games, and no further domain specific knowledge is incorporated.\nThe experiments show that the resulting neural network (referred to as\nDeepChess) is on a par with state-of-the-art chess playing programs, which\nhave been developed through many years of manual feature selection and\ntuning. DeepChess is the first end-to-end machine learning-based method\nthat results in a grandmaster-level chess playing performance.\n\n",
      "Introduction": "1 Introduction\n\nTop computer chess programs are based typically on manual feature selection and\ntuning of their evaluation function, usually through years of trial and error. While\ncomputer chess is one of the most researched fields within AI, machine learning has\nnot been successful yet at producing grandmaster level players.\n\nIn this paper, we employ deep neural networks to learn an evaluation function\nfrom scratch, without incorporating the rules of the game and using no manually\nextracted features at all. Instead, the system is trained from end to end on a large\ndataset of chess positions.\n\nTraining is done in multiple phases. First, we use deep unsupervised neural net-\nworks for pretraining. We then train a supervised network to select a preferable\nposition out of two input positions. This second network is incorporated into a new\nform of alpha-beta search. A third training phase is used to compress the network\nin order to allow rapid computation.\n\nOur method obtains a grandmaster-level chess playing performance, on a par\nwith top state-of-the-art chess programs. To the best of our knowledge, this is the\nfirst machine learning-based method that is capable of learning from scratch and\nobtains a grandmaster-level performance.\n\n"
    }
  },
  {
    "../articles/90GeorgeSchaeffer.pdf": {
      "Abstract": "Abstract\n\nHuman game players rely heavily on the experience gained by playing over\nthe games of masters. A player may recall a previous game to either obtain\nthe best move (if he has previously seen the identical position) or suggest a\nbest move (if similar to others seen). However, game-playing programs\noperate in isolation, relying on the combination of search and programmed\nknowledge to discover the best move, even in positions well-known to\nhumans. At best, programs have only a limited amount of information about\nprevious games. This paper discusses enhancing a chess-playing program to\ndiscover and extract implicit knowledge from previously played grandmaster\ngames, and using it to improve the chess program\u2019s performance. During a\ngame, a database of positions is queried looking for identical or similar posi-\ntions to those on the board. Similarity measures are determined by chunking\nthe position and using these patterns as indices into the database. Relevant\ninformation is subsequently passed back to the chess program and used in its\ndecision making process. As the number of games in the database increases,\nthe \"experience\" available to the program improves the likelihood that\nrelevant, useful information can be found for a given position.\n\n",
      "Introduction": "1. Introduction\n\nFor many subject areas requiring skills, a large body of previous experience is usu-\nally gathered which can be used as a resource to be studied for improving one\u2019s perfor-\nmance. Unfortunately, most attempts at having machines mimic human behavior are pri-\nmarily concerned with trying to solve the problem in isolation (usually a difficult enough\ntask), without exploiting the available wealth of others\u2019 experience. For many discip-\nlines, this information is not available in machine readable form. Other than using simple\nmemory tables, few programs attempt to take advantage of the acquired wealth of human\nexperience on a particular subject.\n\nFor most games, a player\u2019s strength can be increased by re-playing and analyzing\nhundreds of master-level games. Besides the obvious skills that this can improve, a signi-\nficant side-effect is the human\u2019s ability to remember the games or important fragments\nfrom them. During a game, strong players are frequently able to relate the position on the\nboard to an identical or similar one seen in a game played by themselves or by others.\nThis allows the player to draw on the experience of (possibly) more experienced players.\nFrom these game fragments, one may recall the best move (if identical to a position seen\npreviously) or suggest a move to play (if similar to other games seen). From the com-\nputer game-playing point of view, the finding of identical positions is not interesting;\nopening books used by chess programs are an example of how this can be achieved.\nHowever, the ability to discover similar positions has the potential for providing a signifi-\ncant improvement in a game-playing program\u2019s strength. From a set of similar positions,\na program may be able to extract such information as the move(s) played, the plan or stra-\ntegy followed by the opponents, potential traps or threats, and pitfalls to avoid. If this\ninformation could be reliably extracted, a program could build on the experience gained\nby others. Of course, this problem is just a paradigm of the more general problem of\nlearning from experience.\n\nWith the introduction of chess database programs (such as ChessBase and New in\nChess Base), thousands of recent grandmaster games are now available in machine read-\nable form. For each game, the data consists of the moves played, the names of the\nplayers, and the result. Unfortunately, there is no indication of whether moves were good\nor bad. Given this large, growing body of data, there must be some way of extracting\nuseful information from it.\n\nBuilding on the pioneering work of Chase and Simon (1973a,b) in chess cognition,\nthe notion of chess position similarity is achieved through chunking, breaking positions\napart into their basic familiar patterns. By emulating the methods used by humans for\npattern recognition, chess programs can take advantage of human experience, and apply a\nmore knowledge-based approach to their decision making process. This is in stark con-\ntrast to the current brute-force search tendency.\n\nThis paper describes the design of MACH, (a Master Advisor for CHess). Briefly,\nMACH uses a knowledge base of user-defined chunks to access a collection of grandmas-\nter games. The chunks have been defined by masters and correspond to familiar, fre-\nquently occurring chess patterns. All the positions in the available grandmaster games\nhave been broken into their constituent chunks and organized into a database for quick\nretrieval. When a chess program encounters a new position, MACH chunks it, and then\nreferences the database looking for similar positions (as defined by the chunks present).\nFrom the database, MACH can extract relevant information on what the grandmasters did\nin these positions; this information can be as trivial as the move(s) played or as sophisti-\ncated as the plans or strategies followed.\n\nThis work has attempted to create a prototype process that will interface with a\nchess program to give it a more human-like and informed direction to playing chess. To\nplay chess well requires knowledge and the abilities to search and reason with that\nknowledge. Current systems are largely search based; their reasoning processes are quite\nsimple. MACH is an attempt to strike more of a balance between them.\n\nMACH has been implemented and shown to provide useful advice to a performance\nchess program. Ultimately, the success of grandmaster chess programs will depend on\ntheir ability to build on others\u2019 experience. To work in isolation, computing moves for\npositions well known to humans, enhances the chance for errors. To know what has been\nplayed before in identical or similar positions is a tremendous advantage for helping\ndecide on the move to play. Although our prototype implementation of MACH does not\nrun in real-time for tournament use by a performance chess program, our production ver-\nsion of the program will achieve this.\n\n"
    }
  },
  {
    "../articles/91FeldmannMysliwietzMonien.pdf": {
      "Abstract": "ABSTRACT\n\nWe show how to implement the af-enhancements like iterative deepening, transposition tables,\nhistory tables etc. used in sequential chess programs in a distributed system such that the\ndistributed algorithm profits by these heuristics as well as the sequential does. Moreover the\nmethods we describe are suitable for very large distributed systems. We implemented these\na3-enhancements in the distributed chess program ZUGZWANG. For a distributed system of\n64 processors we obtain a speedup between 28 and 34 running at tournament speed. The basis\nfor this chess program is a distributed af-algorithm with very good load balancing properties\ncombined with the use of a distributed transposition table that grows with the size of the\ndistributed system.\n\n",
      "Introduction": "1. INTRODUCTION\n\nIn this paper we describe a fully distributed chess program ZUGZWANG running on a network\nof Transputers. We present experimental results that show the efficiency of our implementa-\ntion. The good behavior of the sequential a{-algorithm shown by [KM75] mainly poses three\ndifficulties to any distributed algorithm. First, the cutoffs of the sequential algorithm may be\noverlooked by the distributed version resulting in search overhead. Second, the problem of load\nbalancing is very difficult for tree decomposition algorithms. This is caused by the unpredictable\nsize of subproblems as well as by the idle times resulting from iterative deepening. Third, the\n\n\u201cThis work was partly supported by grant no. Mo 285/3-2 from the DFG\ntThe Parsytec GmbH, Aachen provided us with a 32 Transputer system for tournament play\nsequential aJ-algorithm strongly profits by several aG-enhancements as iterative deepening,\ntransposition tables, history tables, killer lists etc.. These aG-enhancements often delay the dis-\ntributed algorithm. For example iterative deepening is inherent sequential and the transposition\ntable should be accessible to all processors in the system.\n\nIn [VM87, FMMV89, FMMV90] we present a distributed aG-algorithm that achieves a speedup\nof 11.5 running on a network of 16 processors. This algorithm shows a very good performance\nwhen searching well ordered game trees. This is due to the Young Brothers Wait Concept\nthat helps to reduce search overhead. Furthermore the algorithm shows very good load _bal-\nancing properties. However the algorithm from [VM87, FMMV89, FMMV90] does not use\naf-enhancements. In this paper we present a distributed chess program using the distributed\naJ-algorithm from [VM87, FMMV89, FMMV90]. The distributed version of this chess program\nprofits by the state-of-the-art af-enhancements as well as the sequential one does. It uses iter-\native deepening, a distributed transposition table, shared history tables and shared killer lists,\nzero-width search and a distributed quiescence search. The transposition table for example is\nimplemented as a distributed transposition table. The loss of work load caused by the iterative\ndeepening algorithm is kept very small by the good load balancing capabilities of our distributed\nalgorithm.\n\nThe reduction of search overhead was one of the main topics in the field of parallel a(-algorithms.\nAkl et.al. proposed the mandatory work first approach in [ABD80]. The PVS algorithm is used\nin [MP85, MOS86, Sch89b, New88, HSN89]. A description of this algorithm can be found in\nMC82]. It evaluates right sons of game tree nodes with a minimal a$-window in parallel and\nhen re-evaluates them if necessary. Processors are assigned to subtrees along the principal\nvariation. Alternatively game tree nodes are evaluated in parallel only if they had acquired an\na$-bound before ([FK88]). Another approach applies in the distributed chess program Waycool\nrunning on a hypercube ([OF88]): if the transposition table proposes some move for a game\nosition then this move is tried first. Parallel evaluation of the other moves is started only if\nhe evaluation of the transposition move yields no cutoff. The PVS algorithm and the approach\nof Ferguson and Korf guarantee that best ordered game trees are searched without any search\noverhead. This leads to very efficient implementations, if the game trees to be searched are close\no the minimal game tree as it is usually the case for sequential chess programs. However, to\nkeep the game trees close to the minimal game tree, the sequential chess programs use several\naf-enhancements. The use of these af-enhancements in a distributed system together with\na distributed af-algorithm with very good load balancing properties is the main topic of this\naper.\n\nIn [MP85] Marsland and Popowich compared the use of local and global transposition ta-\nles. Schaeffer uses a hybrid version of these methods for his chess program Sun Phoenix\n[MOS86, Sch89b]). The same program compares knowledge accumulated in the history tables\nafter every iteration of its iterative deepening algorithm. Newborn ([New88]) tried to overcome\nhe idle times caused by iterative deepening with the UIDPABS algorithm. Zero-width search\naccelerates the sequential af-algorithm. Otto and Felten in [OF88] claimed that this method\ndoes not parallelize as well as the af-algorithm without zero-width search. Therefore they par-\nallelized the af-algorithm without zero-width search. In [Sch89a] Schaeffer stated that speedups\nare strongly tied to the (in)efficiency of the a{-search and that the use of aG-enhancememts in\na parallel implementation of the af-algorithm dramatically affects the performance of a parallel\n\nimplementation. This results in speedups of 5.93 using 16 processors in [HSN89], 5.67 using\n9 processors in [MOS86, Sch89b] and 5.03 using 8 processors in [New88]. Moreover increasing\nhe number of processors either decreases the speedup ([HSN89]) or at least does not increase\nit ([MOS86, Sch89b]). The speedup of 101 using 256 processors presented in [OF88] has been\nachieved by parallelizing a suboptimal version of the sequential a{-algorithm. Another interest-\ning result is the speedup of 12 achieved by Ferguson and Korf in [FK88] for an Othello playing\nrogram using iterative deepening.\n\nOur distributed system achieves speedups of 15.77 running on 16 processors and 25.08 running\non 32 processors searching a 7-ply search on the positions of the Bratko-Kopec experiment\n[BK82]). Very recent experiments show that 64 processors can achieve a speedup of 34 for a\n7-ply search running on tournament speed. This is obtained by the use of a distributed a{-\nalgorithm from [VM87, FMMV89, FMMV90] with very good load balancing properties. The\nmain reason for the good behavior of our distributed chess program however is the fact that\nwe combined a parallelization of the af-enhancements together with the good load balancing\nproperties of our distributed aG-algorithm. We implemented a distributed transposition table,\niterative deepening and a distributed quiescence search. Not yet finished is the implementation\nof a shared history table and shared killer lists that are updated dynamically during the tree\nsearch in the distributed system. It turns out that our chess program is a good chess player too.\nIt played successfully during the 2. Computer Games Olympiad in London 1990.\n\nA short description of some features of our sequential chess program is given in section 2. In\nsections 4. and 5. we describe our distributed chess program. In section 6. we present results\ngained from experiments with up to 64 processors.\n\n"
    }
  },
  {
    "../articles/83CondonThompson.pdf": {
      "Abstract": "Not found",
      "Introduction": "Not found"
    }
  },
  {
    "../articles/07Beal.pdf": {
      "Abstract": "Abstract. The relationship of computer Chess to intelligence is dis-\ncussed, and it is observed that, although current Chess programs are ba-\nsically unintelligent, programs that learn to play Chess are a new frontier\nin the construction of intelligent systems. The definition of intelligent sys-\ntems is then expanded to include systems in which individual humans are\ncomponents, rather than organizers, of intelligence. From this perspec-\ntive, internet communities and universities are observed to be intelligent\nsystems that are undergoing rapid evolution \u2014 a process that Jaap and\nhis students are actively advancing.\n\n",
      "Introduction": "1 Introduction\n\nTam happy to be invited to make a contribution to Jaap\u2019s Liber Amicorum. Our\ncontact goes back a long way. To at least the 1970s, although I am not sure of\n\n974.\n\nphi\n\nand includes such ear.\n\no play Chess would i\n50 years led to a hea\ned the human wor!\n\nNow, in 2007, a $1\n0 can achieve simi\n\neal\n\n$10\nNo\n\nit is clear that curren\n\nintelligence.\n\nhe date. We met through our separate efforts to create Intelligent Systems of\na specific kind. He worked with one called Pion, mine was unnamed, but was\ndubbed BCP by organizers of the first World Computer Chess Championship in\n\nComputer Chess has engaged the attention of scientists, mathematicians and\nosophers since computers were invented. The list of\n\n\u2018amous names is long,\n\ny pioneers as Turing, von Neumann, and Shannon, at or\n\nbefore the dawn of electronic computers, all of whom felt t\n\nhat creating programs\n\nluminate the workings of human intelligence.\n\nThe efforts of hundreds of researchers and hundreds o\n\nf scientific papers over\n\nline-making event in 1997. IBM\u2019s DEEP BLUE, a special-\n\nd champion, Gary\n\npurpose hardware machine combined with equally special!\nKasparov, in a tense match of 6 games.\n\n000 desktop computer with Chess\n\nar levels of play. S\n\nelligent behavior\u201d as we become aware 0!\n\nChess programs i\n\n* Don Beal is a visiting research fellow at t\n\nmation Systems of the Birkbeck University of London. Email:\n\n0, is silicon inte\n\nyet. Even allowing for the tendency of humans to progressively redefine\n\nwhat computer\n\nle \u201cintelligent\u201d. Murray Campbell, the Chess expert on\nsaid \u201cI never considered DEEP BLUE int\nent problem solver on this very specific domain.\u201d However, Gary Kasparov did\nsay that when playing DEEP BLUE it sometimes felt as i\n\n-purpose software de-\n\nprograms for less than\nigence now a reality?\n\n\u201cin-\n\nprograms can achieve,\n\nnclude very little that deserves the ti-\n\nhe DEEP BLUE team\n\nelligent in any way. It\u2019s just an excel-\n\nhe was facing a deep\n\nhe School of Computer Science and Infor-\n\ndonb@dcs.bbk.ac.uk.\n"
    }
  },
  {
    "../articles/09CiancariniFavini 1.pdf": {
      "Abstract": "ABSTRACT\n\nPlagiarism is a growing issue in the field of game-playing\nsoftware. As new ideas and technologies are successfully im-\nplemented in free and commercial programs, they will be\nreused and revisited by later programs until they become\n\nstandard, but on the ot:\n\nher hand the same phenomenon can\n\nlead to accusations and claims of plagiarism, especially in\ncompetitive scenarios such as computer chess tournaments.\n\nEstablishing whether a\n\nprogram is a \u201cclone\u201d or derivative of\n\nanother can be a difficult and subjective task, left to the\njudgment of the individual expert and often resulting in a\nshade of gray rather than black and white verdicts. Tour-\nnaments judges and directors have to decide how similar is\ntoo similar on a case-by-case basis. This paper presents an\nobjective framework under which similarities between game\nprograms can be judged, using chess as a test case.\n\nCategories and Subject Descriptors\n\nD.2.8 [Software Engineering]: Metrics; K.4.1 [Computers\nand Society]: Public Policy Issues\u2014ethics, intellectual prop-\nerty rights; K.5.1 [Legal Aspects of Computing]: Hard-\nware/Software Protection\n\n",
      "Introduction": "1. INTRODUCTION\n\nAccording to Merriam-Webster, to plagiarize is \u201cto steal\nand pass off (the ideas or words of another) as one\u2019s own\u201d, or\n\u201cto use (another\u2019s production) without crediting the source.\u201d\nThis is a particularly sensitive topic in the field of gaming\nsoftware, in which ideas from previous programs are con-\nstantly worked upon and reused by the next generations and\ninnovation is comparatively rarer. A unique situation arises\nwith programs that implement artificial intelligences to play\na well-known game, typically a board game like chess or go,\nor a card game like poker. These programs have a consid-\nerable market and by necessity share common traits since\nthey all play by the same rules; plagiarism cases and ac-\ncusations follow almost automatically from these premises.\nThe situation can only worsen under a competitive scenario\n\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that copies\nbear this notice and the full citation on the first page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and/or a fee.\n\nICFDG 2009 April 26-30, 2009, Orlando, FL, USA.\n\nCopyright 2009 ACM 978-1-60558-437-9 ...$5.00.\n\nGian Piero Favini\nDipartimento di Scienze dell\u2019Informazione\nUniversity of Bologna, Italy\nfavini@cs.unibo.it\n\npitting these Als against each other and allowing the gen-\neral public to compare their moves. This paper stems from\ninvolvement in the examination of chess programs for the\npurpose of plagiarism detection and fitness for tournament\nparticipation under antiplagiarism rules. It provides a more\nobjective framework for tournament judges and directors, as\nwell as experts working for them, to make quantitative de-\ncisions on the originality of a game-playing program when\ncompared to another, while trying to minimize the public\ncontroversy associated with plagiarism cases.\n\nThe paper is organized as follows: in Section 2, we mo-\ntivate our research by citing past and current examples of\nplagiarism controversy in the field. In Section 3, we discuss\nthe problem of originality in the context of computer game\nsoftware, and how it is usually dealt with under tournament\nrules. Section 4 contains an overview of well-known pla-\ngiarism detection ideas and techniques. Section 5 presents\na series of ideas and techniques, which can combined into\na method for making plagiarism less of a concern in game\ntournaments. In Section 6, we test those ideas on a series of\nchess programs to give a practical example of how similar-\nities between chess programs can be detected with as little\neffort and as much accuracy as possible. Finally, Section 7\ncontains conclusions and ideas for future work in the field.\n\n"
    }
  },
  {
    "../articles/ICGA_J_34_2_HHB_Zugzwangs_in_Chess_Studies.pdf": {
      "Abstract": "ABSTRACT\n\nVan der Heijden\u2019s ENDGAME STUDY DATABASE IV, HHDBIV, is the definitive collection of\n76,132 chess studies. The zugzwang position or zug, one in which the side to move would\nprefer not to, is a frequent theme in the literature of chess studies. In this third data-mining of\nHHDBIV, we report on the occurrence of sub-7-man zugs there as discovered by the use of\nCQL and Nalimov endgame tables (EGTs). We also mine those Zugzwang Studies in which a\nzug more significantly appears in both its White-to-move (wtm) and Black-to-move (btm)\nforms. We provide some illustrative and extreme examples of zugzwangs in studies.\n\n",
      "Introduction": "1. INTRODUCTION\n\nThe combination of Van der Heijden\u2019s (2010) study database HHDBIV, Nalimov\u2019s sub-7-man (s7m) endgame\ntables (EGTs), and Bleicher\u2019s (2011) endgame analysis service has already enabled the authors (Bleicher et al,\n"
    }
  },
  {
    "../articles/76Panek.pdf": {
      "Abstract": "Not found",
      "Introduction": "Not found"
    }
  },
  {
    "../articles/19Kamlish.pdf": {
      "Abstract": "Not found",
      "Introduction": "Not found"
    }
  },
  {
    "../articles/96Brockington.pdf": {
      "Abstract": "Not found",
      "Introduction": "1 INTRODUCTION\n\nIn the last twenty years, a number of articles and theses have been written that contain innovative parallel\ngame-tree search algorithms. The authors of the parallel algorithms have shown how their work is unique\nand interesting. In some cases, this has been shown by classifying other algorithms by listing implementation\ndetails (Bal and van Renesse, 1986; Ciancarini, 1994). To the author\u2019s knowledge, no attempt has been made\nto classify the algorithms based solely on their algorithmic properties. A taxonomy would make it easy to\nascertain what has and has not been accomplished in parallel game-tree search. The presentation of this\ntype of taxonomy is the main contribution of this paper.\n\nThe taxonomy will be broken into two major categories: a/-based algorithms, and algorithms based on\nother search paradigms (SSS*, ER, and theoretical methods). For the former category, a table is given to\nisolate the fundamental differences between the algorithms. The table is divided into two parts: the first\npart contains characteristics of the af-based algorithms, while the second part contains details about an\nimplementation of each algorithm. Section 2 describes the various columns given in the table, and then gives\nsome brief details on the algorithms contained therein.\n\nThe algorithms based on other search paradigms are given in Section 3. Due to the varied nature of the\nmethods, a brief description is given for each of the algorithms and no attempt has been made to categorize\nthem to the same extent as the af-based algorithms. The implementation details have not been organized\ninto a table, since some of the algorithms given are of a theoretical nature and have not been implemented\nor simulated.\n\nThe final section deals with some conclusions that can be drawn from the taxonomy.\n\n"
    }
  }
]