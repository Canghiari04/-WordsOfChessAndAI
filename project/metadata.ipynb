{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __WordsOfChessAndAI - Metadati__ \n",
    "\n",
    "#### __Obiettivo__\n",
    "\n",
    "L'obiettivo del Jupyter Notebook presentato consiste nell'estrazione di alcune informazioni mediante l'impiego di librerie in grado di leggere e modificare il contenuto di file PDF. Pertanto, di seguito sono definite le funzioni necessarie per estrapolare dal contesto tali dati, suddivisi in:\n",
    "- DOI\n",
    "- Titolo\n",
    "- Autore\n",
    "- Abstract\n",
    "\n",
    "_DOI_ è l'acronimo di __Digital Object Identifier__, identificativo univoco di risorse digitali. Per poter apprendere tale informazione è necessario utilizzare la _REST API_ fornita da __CrossRef__; CrossRef è un'infrastuttura digitale dedita alle memorizzazione di tutti gli articoli posti in ambito accademico. Di seguito, si percepisce l'importanza del titolo e dell'autore per ogni PDF, affinchè interrogando la _Application Programming Interface_ sia possibile ottenere il DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word = \"abstract\"\n",
    "main_path = \"../articles/\"\n",
    "crossref_url = \"https://api.crossref.org/works/10.1037/0003-066X.59.1.29/agency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_path_files(path: str) -> list:\n",
    "    size = 0\n",
    "    path_files = []\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if not item.endswith(\".pdf\"):\n",
    "            print(\"Not a pdf\", item, \"\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            path_files.append(path + item)\n",
    "            size += 1\n",
    "\n",
    "    return path_files\n",
    "\n",
    "path_files = get_path_files(main_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottenuto ogni singolo percorso dei file, provvedo a convertire il formato PDF nelle immagini appartenenti, in maniera tale che attraverso l'__OCR PyTesseract__ sia in grado di estrarre il testo corrispondente. È possibile notare anche la presenza di una variabile denominata _index_; definisce la linea in cui sia stata individuata la key-word\n",
    "\"__Abstract__\", affinchè, successivamente a qualche attività di manipolazione di stringhe, sia capace di estrapolare il contenuto della sezione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "from typing import Dict\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "class ScannedText:\n",
    "    def __init__(self, index: int, text: str):\n",
    "        self.index = index\n",
    "        self.text = text\n",
    "\n",
    "def convert_file_to_images(path: str) -> list:\n",
    "    try:\n",
    "        return convert_from_path(path)[:2]\n",
    "    except Exception as e:\n",
    "        print(\"Error during conversion from file to image:\", e, \"\\n\")\n",
    "\n",
    "def get_target_word_index(text: str) -> int:\n",
    "    count_line = 0\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        if \"abstract\" in line:\n",
    "            return count_line\n",
    "        \n",
    "        count_line += 1\n",
    "    \n",
    "    return -1\n",
    "\n",
    "def scan_file_to_text(paths: list[str]) -> dict[str, ScannedText]:\n",
    "    dict_scanned_texts: Dict[str, ScannedText] = {}\n",
    "\n",
    "    for path in paths:\n",
    "        images = convert_file_to_images(path)\n",
    "\n",
    "        text = \"\"\n",
    "        try:\n",
    "            for image in images:\n",
    "                text = text + pytesseract.image_to_string(image)\n",
    "\n",
    "            dict_scanned_texts[path] = ScannedText(get_target_word_index(text.lower()), text)\n",
    "        except Exception as e:\n",
    "            print(\"Error during conversion from image to text:\", e) \n",
    "        \n",
    "    return dict_scanned_texts\n",
    "\n",
    "dict_scanned_texts = scan_file_to_text(path_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riepilogando, il dizionario __dict_scanned_text__ possiede una suddivisione key-value come segue:\n",
    "- La chiave corrisponde al percorso dello specifico file\n",
    "- Il valore è un oggetto __ScannedText__, a sua volta composto da un indice attuato per definire la linea in cui sia presente la key-word \"_Abstract_\" e una stringa corrispondente al testo estratto precedentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def remove_white_spaces(index: int, text: str) -> List[str]:\n",
    "    lines = text.splitlines()\n",
    "    first_part = lines[:index + 1]\n",
    "\n",
    "    start_index = index + 1\n",
    "    count_line = start_index\n",
    "\n",
    "    for line in lines[start_index:]:\n",
    "        if len(line) == 0:\n",
    "            count_line += 1\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    second_part = lines[count_line:]\n",
    "    \n",
    "    return first_part + second_part\n",
    "\n",
    "def extract_abstract_lines(index: int, lines: list[str]) -> str:\n",
    "    abstract = \"\"\n",
    "\n",
    "    for line in lines[index:]:\n",
    "        if len(line) == 0:\n",
    "            break\n",
    "\n",
    "        abstract += line + \"\\n\"\n",
    "\n",
    "    return abstract\n",
    "\n",
    "def extract_abstract(dict: dict[str, ScannedText]) -> dict[str, str]:\n",
    "    dict_abstracts: Dict[str, str] = {}\n",
    "\n",
    "    for key in dict.keys():\n",
    "        value = dict.get(key)\n",
    "\n",
    "        if value.index > -1:\n",
    "            abstract_lines = remove_white_spaces(value.index, value.text)\n",
    "            text = extract_abstract_lines(value.index, abstract_lines)\n",
    "        else:\n",
    "            text = \"Not found\"\n",
    "\n",
    "        dict_abstracts[key] = text\n",
    "\n",
    "    return dict_abstracts\n",
    "\n",
    "dict_abstracts = extract_abstract(dict_scanned_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il passo successivo prevede l'utilizzo di alcune informazioni per recuperare i _metadati_ mancanti. Mediante l'impiego di alcune librerie, è possibile estrapolare dal PDF dato alcune informazioni al riguardo. Pertanto, tramite la _funzione ricorsiva_ riportata, sono estrapolati tutti i dati necessari per la costruzione dei _metadati_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potrei ampliare il numero di librerie per l'estrapolazione dei metadati\n",
    "\n",
    "import pymupdf\n",
    "import pdfplumber\n",
    "\n",
    "def get_title_from_dicts(pymupdf: dict[str, str], pdfplumber: dict[str, str]) -> str:\n",
    "    return (pymupdf.get(\"title\") or pdfplumber.get(\"title\") or \"Not found\")\n",
    "\n",
    "def get_author_from_dicts(pymupdf: dict[str, str], pdfplumber: dict[str, str]) -> str:\n",
    "    return (pymupdf.get(\"author\") or pdfplumber.get(\"author\") or \"Not found\")\n",
    "\n",
    "def extract_title_and_author(i: int, len: int, paths: list[str], dict_titles = {}, dict_authors = {}) -> tuple[dict[str, str], dict[str, str]]:\n",
    "    if len == 0:\n",
    "        return (dict_titles, dict_authors)\n",
    "    else:\n",
    "        metadata_pymupdf = pymupdf.open(paths[i]).metadata\n",
    "        metadata_pdfplumber = pdfplumber.open(paths[i]).metadata\n",
    "\n",
    "        title = get_title_from_dicts(metadata_pymupdf, metadata_pdfplumber)\n",
    "        author = get_author_from_dicts(metadata_pymupdf, metadata_pdfplumber)\n",
    "        \n",
    "        dict_titles[paths[i]] = title\n",
    "        dict_authors[paths[i]] = author\n",
    "\n",
    "        extract_title_and_author(i + 1, len - 1, paths)\n",
    "        return (dict_titles, dict_authors)\n",
    "\n",
    "tuple_dict_titles_authors = extract_title_and_author(0, len(path_files), path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during request to CrossRef REST API: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "from crossref.restful import Works\n",
    "\n",
    "dict_titles = tuple_dict_titles_authors[0]\n",
    "dict_authors = tuple_dict_titles_authors[1]\n",
    "\n",
    "work = Works()\n",
    "def make_api_call(title: str, author: str) -> str:\n",
    "    url_request = work.query(bibliographic=title, author=author).url\n",
    "\n",
    "    # Attardare di un certo delay come definito dalla libreria per ogni richiesta successiva\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        request = requests.get(url_request)\n",
    "\n",
    "        if request.status_code == 200:\n",
    "            response = request.json()\n",
    "\n",
    "            message = response.get(\"message\")\n",
    "            items = message.get(\"items\")\n",
    "\n",
    "            for item in items:\n",
    "                if any(title in value for value in item.get(\"title\")):\n",
    "                    return item[\"DOI\"]\n",
    "                                                \n",
    "                continue\n",
    "        else:\n",
    "            raise Exception(\"Error during request to CrossRef REST API: bad status code\")\n",
    "    except Exception as e:\n",
    "        print(\"Error during request to CrossRef REST API:\", e)\n",
    "\n",
    "dict_DOI: Dict[str, str] = {}\n",
    "for path in path_files:\n",
    "    if \"Not found\" in (dict_titles.get(path), dict_authors.get(path)):\n",
    "        continue\n",
    "    else:\n",
    "        DOI = make_api_call(dict_titles.get(path), dict_authors.get(path))\n",
    "        dict_DOI[path] = DOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concludendo, ottenuti i dati presenti, sono organizzati attraverso la helper class __Metadata__. Come da definizione dell'_obiettivo_, ogni istanza possiede le informazioni richieste, oltre a presentare anche il percorso del file in questione. Infine è implementato un _dump_ delle informazioni recuperate tramite l'ausilio di un file __json__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "class Metadata:\n",
    "    def __init__(self, DOI, path, title, author, abstract):\n",
    "        self.DOI = DOI\n",
    "        self.path = path\n",
    "        self.title = title\n",
    "        self.author = author\n",
    "        self.abstract = abstract\n",
    "\n",
    "    def get_dict(self) -> Dict[str, Dict[str, str]]:\n",
    "        return {\n",
    "            path: {\n",
    "                \"DOI\": self.DOI,\n",
    "                \"Title\": self.title,\n",
    "                \"Author\": self.author,\n",
    "                \"Abstract\": self.abstract\n",
    "            }\n",
    "        }\n",
    "\n",
    "list_metadata = []\n",
    "for path in path_files:\n",
    "    list_metadata.append(Metadata(dict_DOI.get(path), path, dict_titles.get(path), dict_authors.get(path), dict_abstracts[path]))\n",
    " \n",
    "list_json = []\n",
    "for metadata in list_metadata:\n",
    "    list_json.append(metadata.get_dict())\n",
    "\n",
    "with open(\"../json/metadata.json\", \"a\") as file:\n",
    "    json.dump(list_json, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
